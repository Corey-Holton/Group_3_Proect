{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25268a05-8b73-44e2-8a50-52b43737b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries for audio processing, data handling, and machine learning\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdb84f4-a827-4b85-86d4-32eb69d7f95b",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e487261f-efa6-4d4c-a19f-9c74e0b024bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features (Mel Spectrogram) from audio files\n",
    "def extract_features(file_path, n_mfcc=40):\n",
    "    \"\"\"\n",
    "    Extract Mel-frequency cepstral coefficients (MFCC) from an audio file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the audio file.\n",
    "    - n_mfcc (int): Number of MFCC features to extract.\n",
    "\n",
    "    Returns:\n",
    "    - mfcc (ndarray): Extracted MFCC features.\n",
    "    \"\"\"\n",
    "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)  # Extract MFCC features\n",
    "    return mfcc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72117b-77a2-4213-b26f-bf7e130e6785",
   "metadata": {},
   "source": [
    "Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9d1dd9-9cb5-45b9-b644-ed5e16f33e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1816, 13, 500, 1), Testing set shape: (454, 13, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "# Directory containing audio files organized by class (e.g., guitar notes)\n",
    "DATA_DIR = 'C:/Users/CJHx6/OneDrive/AI_Class/GIT/Group_3_Project/Resources/guitar-notes/Notes Datasets'\n",
    "\n",
    "# Function to extract features from audio files (as you did earlier)\n",
    "def extract_features(file_path):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Extract features (you can customize this based on your model needs)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # Example feature extraction (MFCCs)\n",
    "    \n",
    "    # Return the extracted features\n",
    "    return mfccs\n",
    "\n",
    "# Collecting all audio files and their labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "for dirpath, dirnames, filenames in os.walk(DATA_DIR):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_paths.append(os.path.join(dirpath, file))\n",
    "            labels.append(os.path.basename(dirpath))  # Assuming folder names are the class labels\n",
    "\n",
    "# Encoding labels into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Extracting features for all audio files\n",
    "features = []\n",
    "for file_path in file_paths:\n",
    "    features.append(extract_features(file_path))\n",
    "\n",
    "# Convert features to numpy array and pad for uniform input shape\n",
    "features = [librosa.util.fix_length(feature, size=500, axis=1) for feature in features]\n",
    "X = np.array(features)\n",
    "X = X[..., np.newaxis]  # Adding channel dimension for CNN\n",
    "\n",
    "# Convert labels to numpy array\n",
    "y = np.array(encoded_labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the splits\n",
    "print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a5b56-a53a-4fe5-9f0f-1807c93526a7",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "817ef4c8-f257-4079-a8c1-9615762911be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "# Building a Convolutional Neural Network (CNN)\n",
    "model = Sequential()\n",
    "\n",
    "# Add Input layer to define input shape\n",
    "model.add(Input(shape=(X_train.shape[1], X_train.shape[2], 1)))  # Define input shape here\n",
    "\n",
    "# First convolutional layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten and add dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_)))  # Output layer for classification\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0662d-85e3-4d54-ad2a-b5d774eae68e",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "169b356e-41fb-44fe-9c32-e4433f6f0fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4870 - loss: 1.4301 - val_accuracy: 0.4604 - val_loss: 1.6661\n",
      "Epoch 2/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 1.3601 - val_accuracy: 0.5242 - val_loss: 1.5988\n",
      "Epoch 3/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5312 - loss: 1.2945 - val_accuracy: 0.5308 - val_loss: 1.5777\n",
      "Epoch 4/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5683 - loss: 1.2733 - val_accuracy: 0.5044 - val_loss: 1.6293\n",
      "Epoch 5/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5665 - loss: 1.2281 - val_accuracy: 0.5022 - val_loss: 1.5763\n",
      "Epoch 6/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5480 - loss: 1.2422 - val_accuracy: 0.5198 - val_loss: 1.5616\n",
      "Epoch 7/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5668 - loss: 1.2074 - val_accuracy: 0.5308 - val_loss: 1.5267\n",
      "Epoch 8/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5634 - loss: 1.1793 - val_accuracy: 0.5088 - val_loss: 1.5675\n",
      "Epoch 9/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5601 - loss: 1.2629 - val_accuracy: 0.5419 - val_loss: 1.5710\n",
      "Epoch 10/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6080 - loss: 1.1211 - val_accuracy: 0.5110 - val_loss: 1.6012\n",
      "Epoch 11/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5642 - loss: 1.2244 - val_accuracy: 0.5088 - val_loss: 1.5804\n",
      "Epoch 12/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5886 - loss: 1.1950 - val_accuracy: 0.5419 - val_loss: 1.5691\n",
      "Epoch 13/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6034 - loss: 1.1085 - val_accuracy: 0.5066 - val_loss: 1.7001\n",
      "Epoch 14/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6249 - loss: 1.0750 - val_accuracy: 0.5507 - val_loss: 1.6167\n",
      "Epoch 15/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5835 - loss: 1.1602 - val_accuracy: 0.5264 - val_loss: 1.6295\n",
      "Epoch 16/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6269 - loss: 1.0513 - val_accuracy: 0.5485 - val_loss: 1.5894\n",
      "Epoch 17/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6096 - loss: 1.1887 - val_accuracy: 0.5396 - val_loss: 1.7505\n",
      "Epoch 18/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6154 - loss: 1.0761 - val_accuracy: 0.5463 - val_loss: 1.6793\n",
      "Epoch 19/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6371 - loss: 1.0501 - val_accuracy: 0.5683 - val_loss: 1.5671\n",
      "Epoch 20/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6135 - loss: 1.0485 - val_accuracy: 0.5485 - val_loss: 1.5611\n",
      "Epoch 21/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6347 - loss: 1.0166 - val_accuracy: 0.5419 - val_loss: 1.5650\n",
      "Epoch 22/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6183 - loss: 1.0166 - val_accuracy: 0.5286 - val_loss: 1.6570\n",
      "Epoch 23/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6174 - loss: 1.0379 - val_accuracy: 0.5705 - val_loss: 1.6090\n",
      "Epoch 24/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6519 - loss: 0.9647 - val_accuracy: 0.5771 - val_loss: 1.5055\n",
      "Epoch 25/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6570 - loss: 0.9709 - val_accuracy: 0.5617 - val_loss: 1.5349\n",
      "Epoch 26/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6526 - loss: 0.9490 - val_accuracy: 0.5529 - val_loss: 1.5942\n",
      "Epoch 27/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6402 - loss: 0.9415 - val_accuracy: 0.5507 - val_loss: 1.5966\n",
      "Epoch 28/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6241 - loss: 0.9596 - val_accuracy: 0.5661 - val_loss: 1.5092\n",
      "Epoch 29/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6734 - loss: 0.9353 - val_accuracy: 0.5749 - val_loss: 1.5844\n",
      "Epoch 30/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6586 - loss: 0.9186 - val_accuracy: 0.5727 - val_loss: 1.6071\n",
      "Epoch 31/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6756 - loss: 0.9398 - val_accuracy: 0.5793 - val_loss: 1.6199\n",
      "Epoch 32/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6856 - loss: 0.8516 - val_accuracy: 0.5419 - val_loss: 1.6757\n",
      "Epoch 33/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6649 - loss: 0.8727 - val_accuracy: 0.5617 - val_loss: 1.6396\n",
      "Epoch 34/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6855 - loss: 0.8595 - val_accuracy: 0.5507 - val_loss: 1.7269\n",
      "Epoch 35/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7007 - loss: 0.8586 - val_accuracy: 0.5837 - val_loss: 1.5453\n",
      "Epoch 36/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6641 - loss: 0.9137 - val_accuracy: 0.5903 - val_loss: 1.5853\n",
      "Epoch 37/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6854 - loss: 0.8610 - val_accuracy: 0.5793 - val_loss: 1.6673\n",
      "Epoch 38/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7032 - loss: 0.8663 - val_accuracy: 0.5639 - val_loss: 1.6225\n",
      "Epoch 39/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7135 - loss: 0.8087 - val_accuracy: 0.5595 - val_loss: 1.7860\n",
      "Epoch 40/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6753 - loss: 0.8520 - val_accuracy: 0.5485 - val_loss: 1.6451\n",
      "Epoch 41/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6836 - loss: 0.8326 - val_accuracy: 0.5771 - val_loss: 1.6812\n",
      "Epoch 42/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6937 - loss: 0.8390 - val_accuracy: 0.5727 - val_loss: 1.7302\n",
      "Epoch 43/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7221 - loss: 0.7736 - val_accuracy: 0.5793 - val_loss: 1.8233\n",
      "Epoch 44/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7286 - loss: 0.7521 - val_accuracy: 0.5837 - val_loss: 1.8236\n",
      "Epoch 45/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7371 - loss: 0.7823 - val_accuracy: 0.5903 - val_loss: 1.6877\n",
      "Epoch 46/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7064 - loss: 0.8017 - val_accuracy: 0.5639 - val_loss: 1.6961\n",
      "Epoch 47/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7530 - loss: 0.7306 - val_accuracy: 0.5749 - val_loss: 1.6971\n",
      "Epoch 48/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7214 - loss: 0.7579 - val_accuracy: 0.5705 - val_loss: 1.7057\n",
      "Epoch 49/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7366 - loss: 0.7375 - val_accuracy: 0.5727 - val_loss: 1.7574\n",
      "Epoch 50/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7239 - loss: 0.8092 - val_accuracy: 0.5573 - val_loss: 1.7371\n",
      "Epoch 51/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7365 - loss: 0.7481 - val_accuracy: 0.5529 - val_loss: 1.7913\n",
      "Epoch 52/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7076 - loss: 0.8274 - val_accuracy: 0.5683 - val_loss: 1.6408\n",
      "Epoch 53/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7273 - loss: 0.7473 - val_accuracy: 0.5705 - val_loss: 1.8084\n",
      "Epoch 54/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7360 - loss: 0.7121 - val_accuracy: 0.5815 - val_loss: 1.8200\n",
      "Epoch 55/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7376 - loss: 0.7281 - val_accuracy: 0.5881 - val_loss: 1.7731\n",
      "Epoch 56/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7368 - loss: 0.7035 - val_accuracy: 0.5881 - val_loss: 1.7258\n",
      "Epoch 57/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7585 - loss: 0.6816 - val_accuracy: 0.5925 - val_loss: 1.7609\n",
      "Epoch 58/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7274 - loss: 0.7208 - val_accuracy: 0.5683 - val_loss: 1.7516\n",
      "Epoch 59/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7115 - loss: 0.7639 - val_accuracy: 0.5749 - val_loss: 1.6685\n",
      "Epoch 60/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7476 - loss: 0.6906 - val_accuracy: 0.5837 - val_loss: 1.7727\n",
      "Epoch 61/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7510 - loss: 0.6893 - val_accuracy: 0.5617 - val_loss: 1.8289\n",
      "Epoch 62/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7554 - loss: 0.7083 - val_accuracy: 0.5815 - val_loss: 1.7709\n",
      "Epoch 63/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7526 - loss: 0.6808 - val_accuracy: 0.5639 - val_loss: 1.8786\n",
      "Epoch 64/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7683 - loss: 0.6165 - val_accuracy: 0.5749 - val_loss: 1.7973\n",
      "Epoch 65/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7454 - loss: 0.7130 - val_accuracy: 0.5925 - val_loss: 1.8274\n",
      "Epoch 66/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7556 - loss: 0.6897 - val_accuracy: 0.5639 - val_loss: 1.8579\n",
      "Epoch 67/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7593 - loss: 0.6540 - val_accuracy: 0.6013 - val_loss: 1.7340\n",
      "Epoch 68/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7880 - loss: 0.6357 - val_accuracy: 0.5947 - val_loss: 1.8979\n",
      "Epoch 69/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7606 - loss: 0.6580 - val_accuracy: 0.5617 - val_loss: 1.8477\n",
      "Epoch 70/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7779 - loss: 0.6531 - val_accuracy: 0.5881 - val_loss: 1.7999\n",
      "Epoch 71/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7688 - loss: 0.6282 - val_accuracy: 0.5771 - val_loss: 1.8654\n",
      "Epoch 72/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7899 - loss: 0.6541 - val_accuracy: 0.5837 - val_loss: 1.8041\n",
      "Epoch 73/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7735 - loss: 0.6267 - val_accuracy: 0.5881 - val_loss: 1.9046\n",
      "Epoch 74/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7839 - loss: 0.6532 - val_accuracy: 0.5793 - val_loss: 2.0886\n",
      "Epoch 75/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7694 - loss: 0.6404 - val_accuracy: 0.5683 - val_loss: 1.9308\n",
      "Epoch 76/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7596 - loss: 0.6331 - val_accuracy: 0.5859 - val_loss: 2.0354\n",
      "Epoch 77/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7821 - loss: 0.6346 - val_accuracy: 0.5881 - val_loss: 1.9930\n",
      "Epoch 78/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7656 - loss: 0.6527 - val_accuracy: 0.5573 - val_loss: 1.9202\n",
      "Epoch 79/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7544 - loss: 0.6898 - val_accuracy: 0.5771 - val_loss: 1.8306\n",
      "Epoch 80/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7691 - loss: 0.6310 - val_accuracy: 0.5705 - val_loss: 2.0385\n",
      "Epoch 81/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7547 - loss: 0.6802 - val_accuracy: 0.5771 - val_loss: 1.9473\n",
      "Epoch 82/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7840 - loss: 0.5980 - val_accuracy: 0.5881 - val_loss: 2.0183\n",
      "Epoch 83/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7757 - loss: 0.6044 - val_accuracy: 0.5727 - val_loss: 2.0435\n",
      "Epoch 84/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7932 - loss: 0.6032 - val_accuracy: 0.5947 - val_loss: 2.0410\n",
      "Epoch 85/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7861 - loss: 0.5640 - val_accuracy: 0.5639 - val_loss: 1.9605\n",
      "Epoch 86/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7913 - loss: 0.5956 - val_accuracy: 0.5859 - val_loss: 2.0219\n",
      "Epoch 87/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8061 - loss: 0.5739 - val_accuracy: 0.5903 - val_loss: 2.0176\n",
      "Epoch 88/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8011 - loss: 0.5775 - val_accuracy: 0.5683 - val_loss: 2.0728\n",
      "Epoch 89/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7962 - loss: 0.5778 - val_accuracy: 0.5991 - val_loss: 2.1564\n",
      "Epoch 90/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7792 - loss: 0.5854 - val_accuracy: 0.5815 - val_loss: 2.0290\n",
      "Epoch 91/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7716 - loss: 0.6181 - val_accuracy: 0.6101 - val_loss: 1.9849\n",
      "Epoch 92/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7996 - loss: 0.5607 - val_accuracy: 0.5727 - val_loss: 2.1087\n",
      "Epoch 93/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8070 - loss: 0.5629 - val_accuracy: 0.5771 - val_loss: 2.1892\n",
      "Epoch 94/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8093 - loss: 0.5354 - val_accuracy: 0.5881 - val_loss: 2.0741\n",
      "Epoch 95/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8026 - loss: 0.5404 - val_accuracy: 0.5837 - val_loss: 2.1596\n",
      "Epoch 96/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7948 - loss: 0.5756 - val_accuracy: 0.5969 - val_loss: 2.0456\n",
      "Epoch 97/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7979 - loss: 0.5834 - val_accuracy: 0.6123 - val_loss: 2.0120\n",
      "Epoch 98/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8120 - loss: 0.5077 - val_accuracy: 0.5793 - val_loss: 2.0050\n",
      "Epoch 99/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7978 - loss: 0.5382 - val_accuracy: 0.5771 - val_loss: 2.0351\n",
      "Epoch 100/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7854 - loss: 0.5648 - val_accuracy: 0.5727 - val_loss: 2.0869\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Saving the trained model for future use\n",
    "model.save('guitar_note_classifier.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08d557-6671-4a4b-8648-f8efbeac7c70",
   "metadata": {},
   "source": [
    "Prediction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6420cd7f-fa9c-406e-905f-2251dfe727c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "[[10  0  0 ...  0  0  0]\n",
      " [ 0  5  0 ...  0  1  0]\n",
      " [ 0  3  4 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  2 ...  8  0  0]\n",
      " [ 0  1  0 ...  0  8  1]\n",
      " [ 0  0  0 ...  0  0  8]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1. E       0.77      0.91      0.83        11\n",
      "  10. C-sharp       0.28      0.38      0.32        13\n",
      "        11. D       0.57      0.36      0.44        11\n",
      "  12. D-sharp       0.56      0.29      0.38        17\n",
      "       13. E1       1.00      0.87      0.93        15\n",
      "       14. F1       0.62      0.62      0.62        13\n",
      "15. F-sharp 1       0.71      0.92      0.80        13\n",
      "       16. G1       0.64      0.39      0.48        18\n",
      "17. G-sharp 1       0.92      0.85      0.88        13\n",
      "       18. A1       0.42      0.62      0.50        13\n",
      "19. A-sharp 1       0.55      0.43      0.48        14\n",
      "         2. F       0.31      0.64      0.42        14\n",
      "       20. B1       0.62      0.50      0.56        10\n",
      "       21. C1       0.22      0.20      0.21        10\n",
      "22. C-sharp 1       0.38      0.45      0.42        11\n",
      "       23. D1       0.62      0.56      0.59         9\n",
      "24. D-sharp 1       0.57      0.36      0.44        11\n",
      "       25. E2       0.82      0.75      0.78        12\n",
      "       26. F2       0.77      1.00      0.87        10\n",
      "27. F-sharp 2       0.20      0.30      0.24        10\n",
      "       28. G2       0.40      0.44      0.42        18\n",
      "29. G-sharp 2       0.73      0.89      0.80         9\n",
      "   3. F-sharp       0.53      0.75      0.62        12\n",
      "       30. A2       0.89      0.80      0.84        10\n",
      "31. A-sharp 2       0.56      0.50      0.53        10\n",
      "       32. B2       0.55      0.55      0.55        11\n",
      "       33. C2       0.38      0.27      0.32        11\n",
      "34. C-sharp 2       0.17      0.10      0.12        10\n",
      "       35. D2       0.39      0.70      0.50        10\n",
      "36. D-sharp 2       0.50      0.38      0.43         8\n",
      "       37. E3       0.92      0.75      0.83        16\n",
      "         4. G       0.31      0.29      0.30        14\n",
      "   5. G-sharp       0.86      0.67      0.75        18\n",
      "         6. A       0.82      0.53      0.64        17\n",
      "   7. A-sharp       0.67      0.80      0.73        10\n",
      "         8. B       0.73      0.62      0.67        13\n",
      "         9. C       0.89      0.89      0.89         9\n",
      "\n",
      "     accuracy                           0.57       454\n",
      "    macro avg       0.59      0.58      0.57       454\n",
      " weighted avg       0.60      0.57      0.57       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the test set\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Confusion matrix to evaluate performance\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, predicted_labels))\n",
    "print(classification_report(y_test, predicted_labels, target_names=label_encoder.classes_))\n",
    "\n",
    "# Function to predict the class of a new audio file\n",
    "def predict_audio(file_path):\n",
    "    \"\"\"\n",
    "    Predicts the label of a given audio file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the audio file.\n",
    "\n",
    "    Returns:\n",
    "    - predicted_label (str): Predicted label for the audio file.\n",
    "    \"\"\"\n",
    "    feature = extract_features(file_path)\n",
    "    feature = librosa.util.fix_length(feature, size=500, axis=1)[..., np.newaxis]\n",
    "    feature = np.expand_dims(feature, axis=0)  # Adding batch dimension\n",
    "    prediction = model.predict(feature)\n",
    "    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "    return predicted_label[0]\n",
    "\n",
    "# Example usage:\n",
    "# print(predict_audio('path_to_new_audio_file.wav'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a74b3-21c7-4055-aa01-1c3fd85e9aa0",
   "metadata": {},
   "source": [
    "Future Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc81e38-dfcb-4409-8a66-27984347ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding functionality to detect and separate guitar notes from songs (to be expanded)\n",
    "# Example: Using audio source separation (librosa's harmonic-percussive source separation)\n",
    "def extract_guitar_notes(audio_file):\n",
    "    \"\"\"\n",
    "    Extract guitar-like harmonic notes from a mixed audio file.\n",
    "\n",
    "    Parameters:\n",
    "    - audio_file (str): Path to the mixed audio file.\n",
    "\n",
    "    Returns:\n",
    "    - harmonic (ndarray): Harmonic component of the audio, likely containing guitar sounds.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    harmonic, _ = librosa.effects.hpss(y)  # Harmonic-Percussive Source Separation\n",
    "    return harmonic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
